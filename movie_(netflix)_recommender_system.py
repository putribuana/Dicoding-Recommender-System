# -*- coding: utf-8 -*-
"""Movie (Netflix) - Recommender System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sC2uaLXVcdTY-cXpU_9xcf4dhQTm3O91

# Movie Recommender System - Content Based Filtering

* Nama : Andi Engku Putribuana
* Email : andiengku1922@gmail.com
* ID Dicoding: putribuana

## Import Library
"""

import os
import re
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

!ls -lha kaggle.json
!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#!/bin/bash
!kaggle datasets download narayan63/netflix-popular-movies-dataset

import zipfile

zip_path = '/content/netflix-popular-movies-dataset.zip'
zip_ref = zipfile.ZipFile(zip_path, 'r')
zip_ref.extractall('netflix/')
zip_ref.close()

netflix = '/content/netflix/n_movies.csv'

df = pd.read_csv(netflix)
df.head(5)

"""## Check Dataset"""

df.info()

df.isnull().sum()

"""### Mengatasi Missing Value

Karena terdapat banyak missing value pada data yaitu pada kolom `year` sebanyak 527, kolom `certificate` sebanyak 3453, kolom `duration` sebanyak 2036, kolom `genre` = 73, kolom `rating` 1173 dan kolom `votes`= 1173, maka dari itu kita akan membersihkannya
"""

df.dropna(inplace=True)

df.info()

"""sekarang, data yg kita miliki berjumlah 5754 baris

## Data Preprocessing

### Cek nilai unik setiap kolom
"""

df.title.unique()

df.year.unique()

"""Pada kolom year, terlihat data tanggal yang bervariasi dengan beberapa pola diantarany :

- (YYYY): Hanya tahun.
- (YYYY– ): Tahun mulai hingga sekarang.
- (YYYY–YYYY): Tahun mulai hingga tahun berakhir.
- (II) (YYYY): Tahun dengan penanda tambahan (II).
- (YYYY–2022): Tahun mulai hingga 2022

maka dari itu, kita akan melakukan perbaikan
"""

def clean_year(year_str):
    """Membersihkan dan mengekstrak tahun dari string."""
    # Menghapus tanda kurung dan spasi ekstra
    year_str = year_str.strip('()').strip()

    # Pola untuk mencocokkan tahun
    match = re.search(r'(\d{4})', year_str)

    if match:
        return match.group(1)  # Mengembalikan tahun jika ditemukan
    else:
        return None  # Mengembalikan None jika tidak ditemukan

# Terapkan fungsi clean_year ke kolom 'year'
df['year'] = df['year'].apply(clean_year)

# Ubah kolom 'year' menjadi tipe data datetime
df['year'] = pd.to_datetime(df['year'], format='%Y', errors='coerce')

"""Cek Hasil perbaikan kolom `year`"""

df.year.unique()

df.certificate.unique()

df.duration.unique()

"""pada kolom durasi juga terlihat pola yang tidak rapi dan tipe datanya masih string, maka dari itu kita akan lakukan perbaikan"""

import re

def clean_duration(duration_str):
    """Membersihkan dan mengekstrak durasi dalam menit dari string."""
    match = re.search(r'(\d+)\s*min', duration_str)
    if match:
        return int(match.group(1))
    else:
        return None  # Mengembalikan None jika tidak ditemukan

# Terapkan fungsi clean_duration ke kolom 'duration'
df['duration'] = df['duration'].apply(clean_duration)

df['duration'] = pd.to_timedelta(df['duration'], unit='m')

df.duration.unique()

df.genre.value_counts()

"""### Ekstraksi List Genre"""

print(df['genre'])

from collections import Counter
# Fungsi untuk mengekstraksi dan merapikan kolom genre
def extract_genre(genre_list):
    if pd.isna(genre_list):
        return []
    # Remove unwanted characters and split
    genres = genre_list.strip('[]').replace('"', '').replace("'", '').split(',')
    return [genre.strip() for genre in genres]  # Clean up each genre

# Apply the function to the genre column
df['genre'] = df['genre'].apply(extract_genre)

# Explode the data to separate genres into individual rows
df_exploded = df.explode('genre')

# Calculate the frequency of each genre using Counter
genre_counter = Counter(df_exploded['genre'])

# Create a DataFrame from the Counter results
genre_counts_df = pd.DataFrame(genre_counter.items(), columns=['genre', 'frequency'])

# Display the DataFrame with genre frequencies
print(genre_counts_df)

df.rating.unique()

df.description.unique()

df.stars.unique()

df.votes.unique()

"""mengganti tipe data `votes` ke numerik"""

df['votes'] = df['votes'].str.replace(',', '').astype(int)

"""### Transformasi Variabel Numerik"""

sns.histplot(df['rating'])

sns.histplot(df['votes'])

"""## EDA"""

df.info()

"""### Kagorikal Fitur"""

objects = ['title','certificate', 'genre', 'description', 'stars']

category_df = df[objects]

category_df.head()

category_df.describe()

objects = ['genre']
category_df[objects].describe()

"""### Numerik (float) Fitur"""

#For Numerical Column
numerical = [col for col in df.columns if df[col].dtype in ['int', 'float64']]

for col in numerical:
    print(f'\nDescriptive statistics for {col}:')
    print(f'Mean: {df[col].mean()}')
    print(f'Median: {df[col].median()}')
    print(f'Mode: {df[col].mode().iloc[0]}')
    print(f'Standard Deviation: {df[col].std()}')
    print(f'Min: {df[col].min()}')
    print(f'Max: {df[col].max()}')
    print(f'25th Percentile: {df[col].quantile(0.25)}')
    print(f'50th Percentile: {df[col].quantile(0.50)}')
    print(f'75th Percentile: {df[col].quantile(0.75)}')

pd.set_option('display.float_format', lambda x: '%.2f' % x)

numeric = ['rating']

desc = df[numeric].describe()
desc.loc['kurtosis'] = df[numeric].kurt()
desc.loc['skewness'] = df[numeric].skew()
desc.loc['variance'] = df[numeric].var()
desc.round(2)

"""### Analisis Data

#### Bagaimana distribusi film berdasarkan tahun rilis?
"""

plt.figure(figsize=(12, 6))
sns.histplot(data=df, x='year', bins=30, color='skyblue', edgecolor='black')
plt.title('Distribusi Film Berdasarkan Tahun Rilis')
plt.xlabel('Tahun Rilis')
plt.ylabel('Jumlah Film')
plt.xticks(rotation=45, ha='right')
plt.show()

"""#### Bagaimana tren peningkatan/penurunan jumlah film yang dirilis setiap tahunnya?"""

year_counts = df.groupby('year')['title'].count().reset_index()
plt.figure(figsize=(12, 6))
sns.lineplot(data=year_counts, x='year', y='title')
plt.title('Tren Jumlah Film yang Dirilis per Tahun')
plt.xlabel('Tahun')
plt.ylabel('Jumlah Film')
plt.xticks(rotation=45, ha='right')
plt.show()

"""#### Film apa saja dengan rating tertinggi tiap tahunnya?"""

highest_rated_per_year = df.loc[df.groupby('year')['rating'].idxmax()]
print(highest_rated_per_year[['title', 'year', 'rating']])

"""#### Film apa saja dengan votes terbanyak setiap tahunnya?"""

most_voted_per_year = df.loc[df.groupby('year')['votes'].idxmax()]
print(most_voted_per_year[['title', 'year', 'votes']])

"""#### Bagaimana distribusi rating film?"""

plt.figure(figsize=(12, 6))
plt.hist(df['rating'], bins=5, color='skyblue', edgecolor='black')
plt.title('Distribusi Rating Film')
plt.xlabel('Rating')
plt.ylabel('Frekuensi')
plt.grid(True)
plt.show()

"""#### Genre apa yang paling disukai?"""

# Calculate the frequency of each genre using Counter
genre_counter = Counter(df_exploded['genre'])

# Create a DataFrame from the Counter results
genre_counts_df = pd.DataFrame(genre_counter.items(), columns=['genre', 'frequency'])

# Mengambil 10 genre teratas
top_10_genres = genre_counts_df.sort_values(by=['frequency'], ascending=False).head(10)

# Plot horizontal barplot untuk 10 genre teratas
plt.figure(figsize=(10, 8))
sns.barplot(data=top_10_genres, y='genre', x='frequency', orient='h', color='skyblue', edgecolor='black')
plt.title('10 Genre yang Paling Sering Muncul')
plt.xlabel('Jumlah')
plt.ylabel('Genre')
plt.show()

"""## Data Preparation

#### Melihat nilai unik pada kolom genre
"""

df['genre'] = df['genre'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)

unique_genres = df['genre'].unique()
print(unique_genres)

"""#### Mengecek kategori genre "drama"
"""

df[df['genre'] == 'Drama']

"""#### Konversi data dengan  Tolist"""

# Convert a Pandas Series to a list:
title_list = df['title'].tolist()

# Convert a specific column with multiple values (like 'genre') to a list of lists:
genre_lists = df['genre'].apply(lambda x: x.split(', ') if isinstance(x, str) else x).tolist()

stars_list = df['rating'].tolist()

array = np.array([1, 2, 3])
list_from_array = array.tolist()

print(len(title_list))
print(len(genre_lists))
print(len(stars_list))

"""#### Membuat dictionary pada data"""

movie_dict = {}
for i in range(len(title_list)):
    movie_id = i
    movie_dict[movie_id] = {
        'title': title_list[i],
        'genre': genre_lists[i],
        'rating': stars_list[i]
    }

movie_dict

movie_df = pd.DataFrame.from_dict(movie_dict, orient='index')
movie_df.head()

data = movie_df
data.sample(5)

"""## TF-IDF"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Ubah list genre menjadi string
data['genre_str'] = data['genre'].apply(lambda x: ' '.join(x))

# Melakukan perhitungan idf pada data genre yang sudah diubah menjadi string
tf.fit(data['genre_str'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

tfidf_matrix = tf.fit_transform(data['genre_str'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.title
).sample(5, axis=1).sample(10, axis=0)

"""## Cosine Similiarity"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['title'], columns=data['title'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap judul
cosine_sim_df.sample(10, axis=1).sample(3, axis=0)

"""## Mendapatkan Rekomendasi

"""

def movie_recommendations(movie_title, similarity_data=cosine_sim_df, items=data[['title', 'genre', 'rating']], k=10):
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak lengkap
    index = similarity_data.loc[:,movie_title].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang sudah dipartisi
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop movie_title agar judul yang dicari tidak direkomendasikan
    closest = closest.drop(movie_title, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

movie_recommendations("Legally High", k=10)

movie_recommendations("Rebellion", k=10)